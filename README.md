
# Project Yolo V3
<p align="center">
   <img src="https://media.giphy.com/media/VYPDYUBR9bGEIYtz5s/giphy.gif?cid=ecf05e47pdggmnkmdmfzgcp00hq8cg5nmxrnb2w5m8e8c36t&ep=v1_gifs_search&rid=giphy.gif&ct=g" width="300">
</p>

## About (Eng)
* Target:
Create a neural network to detect objects in an image. This is a training project for working with computer vision and tensorflow libraries.
* Result:
A neural network was created that was capable of identifying 80 classes in an image with good accuracy (~85%) and working quite quickly.

## About (Rus)
* –¶–µ–ª—å:
–°–æ–∑–¥–∞—Ç—å –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å –¥–ª—è –¥–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –æ–±—ä–µ–∫—Ç–æ–≤ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏. –≠—Ç–æ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–π –ø—Ä–æ–µ–∫—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω—ã–º –∑—Ä–µ–Ω–∏–µ–º –∏ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞–º–∏ tensorflow.
* –†–µ–∑—É–ª—å—Ç–∞—Ç:
–ë—ã–ª–∞ —Å–æ–∑–¥–∞–Ω–∞ –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å, —Å–ø–æ—Å–æ–±–Ω–∞—è –æ–ø—Ä–µ–¥–µ–ª—è—Ç—å 80 –∫–ª–∞—Å—Å–æ–≤ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ —Å —Ö–æ—Ä–æ—à–µ–π —Ç–æ—á–Ω–æ—Å—Ç—å—é (~ 85%) –∏ —Ä–∞–±–æ—Ç–∞—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –±—ã—Å—Ç—Ä–æ.

## –ü—Ä–∏–º–µ—Ä —Ä–∞–±–æ—Ç—ã/Example of work
–í—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ/Input image:
![ML photo](https://github.com/InfinityBlazze/YoloV3CV/assets/131138862/1d175c38-92e4-4561-8719-96d558a5bba9)

–û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ/Output image:
![image](https://github.com/InfinityBlazze/YoloV3CV/assets/131138862/68e92188-53e1-4587-beb8-37539a55ff56)


YOLO ‚Äì —ç—Ç–æ –ø–µ—Ä–µ–¥–æ–≤–∞—è —Å–µ—Ç—å –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –æ–±—ä–µ–∫—Ç–æ–≤ (object detection)
* YOLO –º–æ–∂–µ—Ç –æ–±–Ω–∞—Ä—É–∂–∏–≤–∞—Ç—å —Å—Ä–∞–∑—É –Ω–µ—Å–∫–æ–ª—å–∫–æ –æ–±—ä–µ–∫—Ç–æ–≤, –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å –∫–ª–∞—Å—Å—ã –∏ –∏–¥–µ–Ω—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –æ–±—ä–µ–∫—Ç—ã –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏.
* –í YOLO, —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤ –±—ã–ª–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ –∫–∞–∫ –∑–∞–¥–∞—á–∞ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –∫ —Ä–∞–∑–¥–µ–ª—å–Ω—ã–º –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞—é—â–∏–º —Ä–∞–º–∫–∞–º, —Å –∫–æ—Ç–æ—Ä—ã–º–∏ —Å–≤—è–∑–∞–Ω—ã –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–Ω–æ—Å—Ç–∏ –∫ —Ä–∞–∑–Ω—ã–º –∫–ª–∞—Å—Å–∞–º.
* –ü–æ—Å–∫–æ–ª—å–∫—É YOLO —Å–º–æ—Ç—Ä–∏—Ç –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Ä–∞–∑, –ø–ª–∞–≤–∞—é—â–µ–µ –æ–∫–Ω–æ ‚Äì —ç—Ç–æ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø–æ–¥—Ö–æ–¥. –í–º–µ—Å—Ç–æ —ç—Ç–æ–≥–æ, –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–∞–∑–±–∏–≤–∞–µ—Ç—Å—è —Å –ø–æ–º–æ—â—å—é —Å–µ—Ç–∫–∏ –Ω–∞ —è—á–µ–π–∫–∏ —Ä–∞–∑–º–µ—Ä–æ–º ùëÜ‚àóùëÜ. –ü–æ—Å–ª–µ —ç—Ç–æ–≥–æ –∫–∞–∂–¥–∞—è —è—á–µ–π–∫–∞ –æ—Ç–≤–µ—á–∞–µ—Ç –∑–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –≤–µ—â–µ–π
* –í YOLO –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–æ–¥–µ—Ä–∂–∞—â–∏—Ö —Ä–∞–º–æ–∫ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —è–∫–æ—Ä–Ω—ã–µ —Ä–∞–º–∫–∏ (anchor boxes). 
–Ø–∫–æ—Ä—è –±—ã–ª–∏ —Ä–∞—Å—Å—á–∏—Ç–∞–Ω—ã –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ COCO —Å –ø–æ–º–æ—â—å—é k-means –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏. –í—Å–µ–≥–æ —Å–µ—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–µ—Ç 80 –∫–ª–∞—Å—Å–æ–≤ –æ–±—ä–µ–∫—Ç–æ–≤
* YOLO –∏—Å–ø–æ–ª—å–∑—É–µ—Ç 53 CNN —Å–ª–æ—è (darknet-53) –∏ —Å–æ–µ–¥–∏–Ω–µ–Ω—ã —Å –µ—â—ë 53-–º—è —Å–ª–æ—è–º–∏. –í —Å—É–º–º–µ 106 —Å–ª–æ–µ–≤, –≥–¥–µ 3 —Å–ª–æ—è –æ—Ç–≤–µ—á–∞—é—Ç –∑–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ (82,94,106)
* –í–µ—Ä—Å–∏—è 3 –≤–∫–ª—é—á–∞–µ—Ç –≤ —Å–µ–±—è –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–∞–∂–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤. –ê –∏–º–µ–Ω–Ω–æ: residual blocks (–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–µ –±–ª–æ–∫–∏), skip connections (–ø—Ä–æ–ø—É—Å–∫ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π), –∏ up-sampling (–ø–æ–≤—ã—à–µ–Ω–∏–µ —á–∞—Å—Ç–æ—Ç—ã –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏). –ó–∞ –∫–∞–∂–¥—ã–º —Å–≤–µ—Ä—Ç–æ—á–Ω—ã–º —Å–ª–æ–µ–º (CNN) —Å–ª–µ–¥—É–µ—Ç —Å–ª–æ–π batch normalization (–ø–∞–∫–µ—Ç–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏), Leaky ReLu (—Ñ—É–Ω–∫—Ü–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ —Ä–µ–ª—É).

–î–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ YOLOv3 (You Only Look Once Version 3) –∫–ª—é—á–µ–≤—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –≤–∫–ª—é—á–∞—é—Ç –≤ —Å–µ–±—è:
* –†–µ–∞–ª–∏–∑–∞—Ü–∏—é –Ω–∞ Python, –∏—Å–ø–æ–ª—å–∑—É—è —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è TensorFlow.
* –†–µ–∞–ª–∏–∑–∞—Ü–∏—é –∞–ª–≥–æ—Ä–∏—Ç–º–∞ —è–∫–æ—Ä–Ω—ã—Ö —Ä–∞–º–æ–∫ –∏ –ø–æ–¥–∞–≤–ª–µ–Ω–∏—è –Ω–µ-–º–∞–∫—Å–∏–º—É–º–æ–≤.
* –ë–µ—Ä—ë–º –≥–æ—Ç–æ–≤—ã–µ –≤–µ—Å–∞ DarkNet –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏.
* –ü–æ–¥–∞—á—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ –≤—Ö–æ–¥ –∏ –≤—ã—Ö–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.

–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:
* –ù–∞ –≤—Ö–æ–¥ —Å–µ—Ç–∏ –ø–æ–¥–∞—é—Ç—Å—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ñ–æ—Ä–º—ã (n, 416, 416, 3), –≥–¥–µ n-–∫–æ–ª-–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π,  416- —à–∏—Ä–∏–Ω–∞ –∏ –≤—ã—Å–æ—Ç–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, 3 -  –∫–æ–ª-–≤–æ –∫–∞–Ω–∞–ª–æ–≤ —Ü–≤–µ—Ç–æ–≤ (rgb). –†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –º–æ–∂–Ω–æ –º–µ–Ω—è—Ç—å, –Ω–æ –æ–Ω –¥–æ–ª–∂–µ–Ω –¥–µ–ª–∏—Ç—å—Å—è –Ω–∞ 32 –±–µ–∑ –æ—Å—Ç–∞—Ç–∫–∞ (608, 1024 –∏ —Ç.–¥)
* Images of the form (n, 416, 416, 3) are supplied to the network input, where n is the number of images, 416 is the width and height of the images, 3 is the number of color channels (rgb). The size of the images can be changed, but it must be divisible by 32 without a remainder (608, 1024, etc.)
* –ü—Ä–∏–º–µ—Ä —Ä–∞–±–æ—Ç—ã —è–∫–æ—Ä–µ–π –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
* Example of how anchors work for prediction:

![image](https://github.com/InfinityBlazze/YoloV3CV/assets/131138862/21d56247-c8f2-4940-99ed-b4f7f6874f71)

* –î–∞–ª–µ–µ —Å–µ—Ç—å –ø—Ä–æ—Ö–æ–¥–∏—Ç –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é –∏ —Å–æ–∑–¥–∞–µ—Ç –ø–æ 3 —Ä–∞–º–∫–∏ –Ω–∞ –∫–∞–∂–¥—ã–π –æ–±—ä–µ–∫—Ç. –ò—Å–ø—É–æ–ª—å–∑—É—è —Ñ—É–Ω–∫—Ü–∏—é nonMaximumSuppression –º—ã –æ—Ç–±—Ä–∞—Å—ã–≤–∞–µ–º —Ä–∞–º–∫–∏ —Å –Ω–∞–∏–º–µ–Ω—å—à–∏–º –ø—Ä–æ—Ü–µ–Ω—Ç–æ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏.
* Next, the network passes through the image and creates 3 frames for each object. Using the nonMaximumSuppression function, we discard frames with the lowest percentage of probability.

![image](https://github.com/InfinityBlazze/YoloV3CV/assets/131138862/2069f460-e1c0-4ddc-9a39-d5f1a35f051a)
    
* –ù–∞ –≤—ã—Ö–æ–¥–µ –º—ã –ø–æ–ª—É—á–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å —Ä–∞–º–∫–æ–π, —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é (–≤ %) –∏ –Ω–∞–∑–≤–∞–Ω–∏–µ–º –æ–±—ä–µ–∫—Ç–∞.
* At the output we get a processed image with a frame, confidence (in%) and the name of the object.

# Some info about project
  YOLO is an advanced network for object detection
* YOLO can detect multiple objects at once, predict classes and identify objects in an image.
* In YOLO, object recognition was implemented as a regression problem to separate bounding boxes with associated probabilities of membership in different classes.
* Since YOLO only looks at an image once, a floating window is the wrong approach. Instead, the entire image is divided using a grid into cells of size ùëÜ‚àóùëÜ. After that, each cell is responsible for predicting several things
* YOLO uses anchor boxes to predict containing boxes.
Anchors were calculated on the COCO dataset using k-means clustering. In total, the network recognizes 80 object classes
* YOLO uses 53 CNN layers (darknet-53) and is connected to another 53 layers. A total of 106 layers, where 3 layers are responsible for detection (82,94,106)
*Version 3 includes several important elements. Namely: residual blocks, skip connections, and up-sampling. Each convolutional layer (CNN) is followed by a batch normalization layer, Leaky ReLu (relu activation function).

To create a YOLOv3 (You Only Look Once Version 3) model, key components include:
* Implementation in Python using the TensorFlow deep learning framework.
* Implementation of the algorithm for anchor frames and suppression of non-maxima.
* We take ready-made DarkNet weights from the original trained model.
* Feeding the image to the input and output of the processed image.

